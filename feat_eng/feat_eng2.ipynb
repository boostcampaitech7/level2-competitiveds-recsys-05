{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 클러스터 별로 각 클러스터 Prophet 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 파일 경로 및 파일 불러오기\n",
    "data = pd.read_csv('/data/ephemeral/home/level2-competitiveds-recsys-05/notebooks/JWORGINIZETEST/train_label.csv')\n",
    "data = data[data['_type'] == 'train']\n",
    "# data = data[data['contract_year_month'] == 202303]\n",
    "\n",
    "data = data.groupby(['complex_id', 'latitude', 'longitude'], as_index=False).agg({\n",
    "    'area_m2' : 'mean',\n",
    "    'deposit' : 'mean',\n",
    "    'built_year' : 'min'\n",
    "})\n",
    "\n",
    "\n",
    "# complex_id 기준으로 위도(latitude), 경도(longitude) 값만 추출\n",
    "data = data.drop_duplicates(subset=['complex_id', 'area_m2'])\n",
    "data = data.sort_values(by = ['latitude', 'longitude'])\n",
    "\n",
    "# 데이터 형태 확인\n",
    "print(\"데이터 형태:\", data.shape)\n",
    "print(data.head())  # 첫 5개 행 출력\n",
    "\n",
    "# 사용할 변수 선택 \n",
    "selected_columns = ['latitude', 'area_m2', 'built_year', 'longitude', 'deposit']\n",
    "\n",
    "# 데이터 전처리 함수 호출\n",
    "processed_data = select_and_preprocess_data(\n",
    "    data=data,\n",
    "    selected_columns=selected_columns,\n",
    "    scaling_method='standard',  # 'standard' 또는 'minmax', 'robust'\n",
    "    sample_size=None,           # 샘플링하지 않음\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"전처리된 데이터의 형태:\", processed_data.shape)\n",
    "\n",
    "# 차원 축소 알고리즘 선택 및 파라미터 설정\n",
    "dr_method = 'UMAP'\n",
    "dr_params = {'n_components': 2}\n",
    "\n",
    "# 차원 축소 적용\n",
    "reduced_data, dr_used_params = apply_dimensionality_reduction(\n",
    "    method=dr_method,\n",
    "    data=processed_data,\n",
    "    tune_hyperparameters=False,\n",
    "    custom_params=dr_params,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"차원 축소된 데이터의 형태: {reduced_data.shape}\")\n",
    "print(f\"사용된 차원 축소 파라미터: {dr_used_params}\")\n",
    "\n",
    "# 클러스터링 알고리즘 선택 및 파라미터 설정\n",
    "cl_method = 'KMeans'\n",
    "cl_params = {'n_clusters': 1000}\n",
    "\n",
    "# 클러스터링 적용\n",
    "model, labels, cl_used_params = apply_clustering(\n",
    "    method=cl_method,\n",
    "    data=reduced_data,\n",
    "    tune_hyperparameters=False,\n",
    "    custom_params=cl_params,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"클러스터 레이블의 형태: {labels.shape}\")\n",
    "\n",
    "print(f\"사용된 클러스터링 파라미터: {cl_used_params}\")\n",
    "\n",
    "data2 = pd.read_csv('/data/ephemeral/home/level2-competitiveds-recsys-05/notebooks/EDA&FE/final.csv')\n",
    "data['cluster_labels2'] = labels\n",
    "cluster_data = data[['cluster_labels2', 'complex_id']]\n",
    "\n",
    "data3 = data2.merge(cluster_data, on=['complex_id'], how='left')\n",
    "data3.to_csv('final2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "\n",
    "data = pd.read_csv('./final2.csv)\n",
    "\n",
    "# 최종 결과를 저장할 빈 데이터프레임 생성\n",
    "final_results = pd.DataFrame()\n",
    "\n",
    "# 1. 데이터를 cluster_labels2로 그룹화\n",
    "grouped = data.groupby('cluster_labels2')\n",
    "\n",
    "# 2. 각 클러스터별로 데이터 처리 및 예측\n",
    "for cluster, group_data in grouped:\n",
    "    # contract_year_month에서 연도와 월을 추출하여 반기 구분\n",
    "    group_data['contract_year_month'] = group_data['contract_year_month'].astype(str)\n",
    "    group_data['year'] = group_data['contract_year_month'].str[:4].astype(int)\n",
    "    group_data['month'] = group_data['contract_year_month'].str[4:6].astype(int)\n",
    "    \n",
    "    # 반기 구분 (1~6월 상반기, 7~12월 하반기)\n",
    "    group_data['half_year'] = group_data['month'].apply(lambda x: 'H1' if x <= 6 else 'H2')\n",
    "    \n",
    "    # 반기별 deposit 값 평균 계산\n",
    "    semi_annual_data = group_data.groupby(['year', 'half_year']).agg({'deposit': 'mean'}).reset_index()\n",
    "    \n",
    "    # 반기를 실제 날짜로 변환하는 함수\n",
    "    def half_year_to_date(row):\n",
    "        if row['half_year'] == 'H1':  # 상반기 -> 해당 연도의 6월 30일로 설정\n",
    "            return pd.Timestamp(year=row['year'], month=6, day=30)\n",
    "        else:  # 하반기 -> 해당 연도의 12월 31일로 설정\n",
    "            return pd.Timestamp(year=row['year'], month=12, day=31)\n",
    "\n",
    "    # 'ds' 컬럼에 날짜 생성\n",
    "    semi_annual_data['ds'] = semi_annual_data.apply(half_year_to_date, axis=1)\n",
    "    semi_annual_data = semi_annual_data[['ds', 'deposit']].rename(columns={'deposit': 'y'})\n",
    "    \n",
    "    # Prophet 모델로 예측\n",
    "    model = Prophet()\n",
    "    model.fit(semi_annual_data)\n",
    "\n",
    "    # 2024년 상반기 예측 (한 시점 예측)\n",
    "    future = model.make_future_dataframe(periods=1, freq='6M')\n",
    "    forecast = model.predict(future)\n",
    "    predicted_2024_h1 = forecast[['ds', 'yhat']].tail(1)['yhat'].values[0]  # 2024 상반기 예측값\n",
    "\n",
    "    # 3. 원본 데이터에 mean_cluster_prophet 컬럼 추가\n",
    "    group_data['mean_cluster_prophet'] = None  # 빈 컬럼 생성\n",
    "\n",
    "    # 기존 반기별 평균을 mean_cluster_prophet에 할당\n",
    "    for i, row in semi_annual_data.iterrows():\n",
    "        mask = (group_data['year'] == row['ds'].year) & (group_data['half_year'] == ('H1' if row['ds'].month == 6 else 'H2'))\n",
    "        group_data.loc[mask, 'mean_cluster_prophet'] = row['y']\n",
    "\n",
    "    # 2024년 상반기에는 예측값을 넣어줌\n",
    "    group_data.loc[(group_data['year'] == 2024) & (group_data['half_year'] == 'H1'), 'mean_cluster_prophet'] = predicted_2024_h1\n",
    "\n",
    "    # 클러스터별 데이터를 최종 결과에 저장\n",
    "    final_results = pd.concat([final_results, group_data], ignore_index=True)\n",
    "\n",
    "# 최종 데이터를 파일로 저장\n",
    "final_results.to_csv('cluster_mean_prophet_results.csv', index=False)\n",
    "\n",
    "print(\"클러스터별 예측 및 반기 평균 값이 'cluster_mean_prophet_results.csv' 파일로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 지하철역 환승 허브와의 거리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "data = pd.read_csv('/data/ephemeral/home/level2-competitiveds-recsys-05/notebooks/data/subwayInfo.csv')\n",
    "\n",
    "# 1km 이내에 있는 지하철역 개수를 세는 함수\n",
    "def count_nearby_stations(row, data, radius=0.1):\n",
    "    count = 0\n",
    "    for idx, station in data.iterrows():\n",
    "        if row.name != idx:  # 자기 자신은 제외\n",
    "            distance = geodesic((row['latitude'], row['longitude']), (station['latitude'], station['longitude'])).km\n",
    "            if distance <= radius:\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "# 각 지하철역에 대해 1km 이내에 있는 지하철역 개수 계산\n",
    "data['nearby_stations'] = data.apply(count_nearby_stations, axis=1, data=data)\n",
    "\n",
    "# 결과 확인\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "\n",
    "# 각 행마다 가장 가까운 교통 허브의 거리를 계산하는 함수\n",
    "def find_nearest_hub(row, sub_4):\n",
    "    min_distance = float('inf')\n",
    "    for idx, hub in sub_4.iterrows():\n",
    "        distance = geodesic((row['latitude'], row['longitude']), (hub['latitude'], hub['longitude'])).km\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "    return min_distance\n",
    "\n",
    "# 각 행마다 nearest_transportation_hub 계산\n",
    "data['nearest_transportation_hub'] = data.apply(find_nearest_hub, axis=1, sub_4=sub_4)\n",
    "\n",
    "# 결과 확인\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Park FE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "parkdata = pd.read_csv('/data/ephemeral/home/level2-competitiveds-recsys-05/notebooks/data/newparkInfo.csv')\n",
    "complexdata = pd.read_csv('/data/ephemeral/home/level2-competitiveds-recsys-05/notebooks/EDA&FE/max_train_updated_clean.csv')\n",
    "complexdata = complexdata.drop_duplicates(subset=['complex_id', 'latitude', 'longitude'])\n",
    "complexdata = complexdata[['complex_id', 'latitude', 'longitude']]\n",
    "\n",
    "# Parkdata에서 area가 10만 이상인 값 필터링\n",
    "filtered_parkdata = parkdata[parkdata['area'] >= 100000]\n",
    "\n",
    "# 각 공원 주변 1.5km 이내의 complexdata 개수를 세는 함수\n",
    "def count_nearby_complexes(row, complexdata, radius=1.5):\n",
    "    count = 0\n",
    "    for idx, complex_row in complexdata.iterrows():\n",
    "        distance = geodesic((row['latitude'], row['longitude']), (complex_row['latitude'], complex_row['longitude'])).km\n",
    "        if distance <= radius:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "# 각 공원에 대해 1.5km 이내에 있는 complexdata 개수 계산\n",
    "filtered_parkdata['nearby_complexes'] = filtered_parkdata.apply(count_nearby_complexes, axis=1, complexdata=complexdata)\n",
    "\n",
    "# 1.5km 이내에 complexdata가 10개 이상인 공원 필터링\n",
    "result = filtered_parkdata[filtered_parkdata['nearby_complexes'] >= 10]\n",
    "\n",
    "# 결과 확인\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## deposit 증감 추세 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('/data/ephemeral/home/level2-competitiveds-recsys-05/notebooks/data/fe_final_2.csv')\n",
    "\n",
    "data = data.groupby('contract_year_month', as_index=False).agg({\n",
    "    'deposit' : 'mean',\n",
    "    'area_m2' : 'mean',\n",
    "    'floor' : 'mean',\n",
    "    'previous_month_interest_rate' : 'first',\n",
    "    'age' : 'mean',\n",
    "    'contract_count_last_month' : 'mean',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 변수\n",
    "data['year'] = data['contract_year_month'].astype(str).str[:4].astype(int)\n",
    "data['month'] = data['contract_year_month'].astype(str).str[4:6].astype(int)\n",
    "\n",
    "# 전월 대비 변화율 변수 생성\n",
    "data['area_m2_diff'] = data['area_m2'].diff()\n",
    "data['floor_diff'] = data['floor'].diff()\n",
    "data['interest_rate_diff'] = data['previous_month_interest_rate'].diff()\n",
    "data['age_diff'] = data['age'].diff()\n",
    "data['contract_count_last_month_diff'] = data['contract_count_last_month'].diff()\n",
    "\n",
    "# 이동 평균 변수 생성\n",
    "data['area_m2_ma'] = data['area_m2'].rolling(window=3).mean()\n",
    "data['floor_ma'] = data['floor'].rolling(window=3).mean()\n",
    "data['interest_rate_ma'] = data['previous_month_interest_rate'].rolling(window=3).mean()\n",
    "data['age_ma'] = data['age'].rolling(window=3).mean()\n",
    "data['contract_count_last_month_ma'] = data['contract_count_last_month'].rolling(window=3).mean()\n",
    "data['time_index'] = range(len(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# 독립 변수와 종속 변수 설정\n",
    "# 여기서 독립 변수로 사용할 컬럼들 선택 (예시로 일부 사용)\n",
    "# Step 1: 데이터 분할\n",
    "train_data = data[data['contract_year_month'] <= 202312]  # 202312 이전 데이터\n",
    "test_data = data[(data['contract_year_month'] >= 202401) & (data['contract_year_month'] <= 202406)]  # 202401 ~ 202406 데이터\n",
    "\n",
    "# 학습을 위한 독립 변수와 종속 변수 설정\n",
    "X_train = train_data.drop(['deposit'], axis=1)\n",
    "y_train = train_data['deposit']\n",
    "\n",
    "# 테스트 데이터를 위한 독립 변수 설정\n",
    "X_test = test_data.drop(columns=['deposit'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 선형회귀 모델 학습\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 회귀 계수 확인\n",
    "coefficients = model.coef_\n",
    "intercept = model.intercept_\n",
    "\n",
    "# 인덱스 생성\n",
    "# 회귀 계수를 X 데이터에 곱하고 가중합 계산\n",
    "train_data['deposit_index'] = np.dot(X_train, coefficients) + intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 증감 방향 계산\n",
    "# 현재와 이전 값의 차이를 계산\n",
    "train_data['deposit_change'] = train_data['deposit'].diff().fillna(0)\n",
    "train_data['deposit_index_change'] = train_data['deposit_index'].diff().fillna(0)\n",
    "\n",
    "# 증감 방향 비교\n",
    "train_data['same_direction'] = np.where(\n",
    "    (train_data['deposit_change'] > 0) & (train_data['deposit_index_change'] > 0) | \n",
    "    (train_data['deposit_change'] < 0) & (train_data['deposit_index_change'] < 0),\n",
    "    1,  # 같은 방향\n",
    "    0   # 다른 방향\n",
    ")\n",
    "\n",
    "# 비율 계산\n",
    "same_direction_ratio = train_data['same_direction'].mean()\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"증감 방향이 같은 비율: {same_direction_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: 202401 ~ 202406 데이터 선택\n",
    "forecast_data = data[(data['contract_year_month'] >= 202401) & (data['contract_year_month'] <= 202406)]\n",
    "\n",
    "# 독립 변수 준비\n",
    "X_forecast = forecast_data.drop(['deposit'], axis=1)\n",
    "\n",
    "# Step 4: 예측 수행\n",
    "forecast_data['deposit_index'] = np.dot(X_test, model.coef_) + model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['deposit_change'] = train_data['deposit'].diff().fillna(0)\n",
    "train_data['deposit_index_change'] = train_data['deposit_index'].diff().fillna(0)\n",
    "forecast_data['deposit_index_change'] = forecast_data['deposit_index'].diff().fillna(0)\n",
    "\n",
    "data = pd.concat([train_data, forecast_data])\n",
    "\n",
    "data2 = data[['contract_year_month','deposit_index', 'deposit_index_change']]\n",
    "\n",
    "data2.to_csv('deposit_index.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex 밀집도 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "# 샘플 데이터 로딩 (경도, 위도 정보가 포함된 데이터프레임)\n",
    "data = pd.read_csv('your_data.csv')\n",
    "\n",
    "# K-D Tree 생성\n",
    "tree = cKDTree(data[['latitude', 'longitude']].values)\n",
    "\n",
    "# 각 지점에 대해 반경 1km 이내의 개수 계산\n",
    "def count_nearby_stations(row, tree, radius=1):\n",
    "    # 위도, 경도를 쿼리하여 반경 내 지점 찾기 (1km = 약 0.009 degrees)\n",
    "    indices = tree.query_ball_point([row['latitude'], row['longitude']], r=radius / 111)\n",
    "    return len(indices) - 1  # 자기 자신 제외\n",
    "\n",
    "data['near_complex_num'] = data.apply(lambda row: count_nearby_stations(row, tree), axis=1)\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## interestRate 기울기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 파일 불러오기\n",
    "interest_rate_df = pd.read_csv(file_path + 'interestRate.csv')\n",
    "\n",
    "# index 기준으로 역순 정렬\n",
    "interest_rate_df = interest_rate_df.sort_index(ascending=False).reset_index(drop=True)\n",
    "\n",
    "# 기울기를 계산할 함수 정의\n",
    "def calculate_slope(series):\n",
    "    if len(series) < 3:\n",
    "        return np.nan  # 데이터가 3개월 미만일 때는 NaN 처리\n",
    "    x = np.array(range(len(series)))\n",
    "    y = np.array(series)\n",
    "    slope = np.polyfit(x, y, 1)[0]  # 기울기 계산\n",
    "    return slope\n",
    "\n",
    "# 3개월치의 기울기를 계산해서 새로운 열로 추가\n",
    "interest_rate_df['3_month_slope'] = interest_rate_df['interest_rate'].rolling(window=3).apply(calculate_slope, raw=True)\n",
    "\n",
    "# 첫 번째 NaN 값 대체\n",
    "first_valid_slope = interest_rate_df['3_month_slope'].dropna().iloc[0]\n",
    "interest_rate_df['3_month_slope'].fillna(first_valid_slope, inplace=True)\n",
    "\n",
    "# index 0은 0으로 대체\n",
    "interest_rate_df.loc[0, '3_month_slope'] = 0\n",
    "\n",
    "# index 1은 2개월치의 기울기로 계산\n",
    "if len(interest_rate_df) > 1:\n",
    "    x = np.array([0, 1])\n",
    "    y = interest_rate_df.loc[0:1, 'interest_rate']\n",
    "    two_month_slope = np.polyfit(x, y, 1)[0]\n",
    "    interest_rate_df.loc[1, '3_month_slope'] = two_month_slope\n",
    "\n",
    "# df와 interest_rate_df를 'contract_year_month'를 기준으로 병합\n",
    "df = pd.merge(df, interest_rate_df[['contract_year_month', '3_month_slope']], \n",
    "              on='contract_year_month', \n",
    "              how='left')\n",
    "\n",
    "# 결과 확인\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical 변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('/data/ephemeral/home/level2-competitiveds-recsys-05/notebooks/code copy/final2.csv')\n",
    "\n",
    "# 변수 목록\n",
    "variables = ['area_m2', 'floor', 'built_year', \n",
    "             'max_deposit_per_area', 'previous_deposit2', 'nearest_transportation_hub']\n",
    "\n",
    "# 카테고리 수\n",
    "num_categories = 6\n",
    "\n",
    "# 각 변수에 대해 min-max 스케일링과 카테고리화\n",
    "for var in variables:\n",
    "    # Min-max 스케일링\n",
    "    scaled_values = (data[var] - data[var].min()) / (data[var].max() - data[var].min())\n",
    "    \n",
    "    # 카테고리화\n",
    "    data[f'{var}_categorical'] = pd.cut(scaled_values, bins=num_categories, labels=[i+1 for i in range(num_categories)])\n",
    "\n",
    "# 결과 확인\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous deposit 값 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 정렬\n",
    "df = df.sort_values(by=['complex_id', 'area_m2', 'contract_year_month', 'contract_day']).reset_index(drop=True)\n",
    "\n",
    "# 2. 월별 deposit 평균 계산\n",
    "monthly_avg_deposit = df.groupby('contract_year_month')['deposit'].mean().to_dict()\n",
    "\n",
    "# 3. 이전 deposit 가져오기: shift\n",
    "df['previous_deposit'] = df.groupby(['complex_id', 'area_m2'])['deposit'].shift(1)\n",
    "\n",
    "# 4. 첫 번째 거래에서 previous_deposit가 NaN이고, deposit이 존재하는 경우 처리\n",
    "df['transaction_order'] = df.groupby(['complex_id', 'area_m2']).cumcount()\n",
    "mask = (df['previous_deposit'].isna()) & (df['transaction_order'] == 0) & (df['deposit'].notna())\n",
    "df.loc[mask, 'previous_deposit'] = df.loc[mask, 'deposit']\n",
    "\n",
    "# 5. 증감 비율 적용하여 previous_deposit 보정\n",
    "def adjust_deposit_with_ratio(row):\n",
    "    if pd.isna(row['previous_deposit']):\n",
    "        return np.nan # 결측이면 패스\n",
    "\n",
    "    prev_month = row['contract_year_month_prev']\n",
    "    curr_month = row['contract_year_month']\n",
    "\n",
    "    # 월별 deposit 평균 가져오기\n",
    "    if prev_month in monthly_avg_deposit and curr_month in monthly_avg_deposit:\n",
    "        ratio = monthly_avg_deposit[curr_month] / monthly_avg_deposit[prev_month]\n",
    "    else:\n",
    "        ratio = 1 # 평균이 없을 경우 비율을 1로 설정\n",
    "\n",
    "    # previous_deposit 비율 적용\n",
    "    return row['previous_deposit'] * ratio\n",
    "\n",
    "df['contract_year_month_prev'] = df.groupby(['complex_id', 'area_m2'])['contract_year_month'].shift(1)\n",
    "\n",
    "# 6. 보정된 previous_deposit 적용\n",
    "df['previous_deposit2'] = df.apply(adjust_deposit_with_ratio, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. remaining NaN 값 처리 (기존 로직 유지)\n",
    "valid_deposits = df[df['deposit'].notna()]\n",
    "last_valid_deposits = valid_deposits.groupby(['complex_id', 'area_m2'])['deposit'].last().reset_index()\n",
    "\n",
    "complex_id_to_area_deposit = {}\n",
    "for complex_id, group in last_valid_deposits.groupby('complex_id'):\n",
    "    area_m2_values = group['area_m2'].values\n",
    "    deposit_values = group['deposit'].values\n",
    "    complex_id_to_area_deposit[complex_id] = (area_m2_values, deposit_values)\n",
    "\n",
    "missing_prev_deposit_idx = df[df['previous_deposit'].isna()].index\n",
    "missing_prev_deposit_rows = df.loc[missing_prev_deposit_idx]\n",
    "\n",
    "for complex_id, group in missing_prev_deposit_rows.groupby('complex_id'):\n",
    "    if complex_id in complex_id_to_area_deposit:\n",
    "        valid_area_m2_values, valid_deposit_values = complex_id_to_area_deposit[complex_id]\n",
    "        missing_area_m2_values = group['area_m2'].values\n",
    "\n",
    "        # numpy를 사용하여 가장 가까운 area_m2 찾기\n",
    "        diff = np.abs(missing_area_m2_values[:, np.newaxis] - valid_area_m2_values[np.newaxis, :])\n",
    "        min_idx = diff.argmin(axis=1)\n",
    "\n",
    "        # 해당 deposit 값 가져오기\n",
    "        deposit_values_to_fill = valid_deposit_values[min_idx]\n",
    "\n",
    "        # previous_deposit 컬럼 업데이트\n",
    "        df.loc[group.index, 'previous_deposit'] = deposit_values_to_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. remaining NaN 값 처리 (기존 로직 유지)\n",
    "valid_deposits = df[df['deposit'].notna()]\n",
    "last_valid_deposits = valid_deposits.groupby(['complex_id', 'area_m2'])['deposit'].last().reset_index()\n",
    "\n",
    "complex_id_to_area_deposit = {}\n",
    "for complex_id, group in last_valid_deposits.groupby('complex_id'):\n",
    "    area_m2_values = group['area_m2'].values\n",
    "    deposit_values = group['deposit'].values\n",
    "    complex_id_to_area_deposit[complex_id] = (area_m2_values, deposit_values)\n",
    "\n",
    "missing_prev_deposit_idx = df[df['previous_deposit2'].isna()].index\n",
    "missing_prev_deposit_rows = df.loc[missing_prev_deposit_idx]\n",
    "\n",
    "for complex_id, group in missing_prev_deposit_rows.groupby('complex_id'):\n",
    "    if complex_id in complex_id_to_area_deposit:\n",
    "        valid_area_m2_values, valid_deposit_values = complex_id_to_area_deposit[complex_id]\n",
    "        missing_area_m2_values = group['area_m2'].values\n",
    "\n",
    "        # numpy를 사용하여 가장 가까운 area_m2 찾기\n",
    "        diff = np.abs(missing_area_m2_values[:, np.newaxis] - valid_area_m2_values[np.newaxis, :])\n",
    "        min_idx = diff.argmin(axis=1)\n",
    "\n",
    "        # 해당 deposit 값 가져오기\n",
    "        deposit_values_to_fill = valid_deposit_values[min_idx]\n",
    "\n",
    "        # previous_deposit 컬럼 업데이트\n",
    "        df.loc[group.index, 'previous_deposit2'] = deposit_values_to_fill"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
