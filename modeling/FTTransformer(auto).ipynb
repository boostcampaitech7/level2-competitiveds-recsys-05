{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# 파일 경로 설정\n",
    "file_path = '../data/'\n",
    "\n",
    "# 파일 불러오기\n",
    "df = pd.read_csv(file_path + '123.csv')\n",
    "sample_submission = pd.read_csv(file_path + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test split\n",
    "train = df[df[\"_type\"] == \"train\"]\n",
    "test = df[df[\"_type\"] == \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "holdout_start = 202307\n",
    "holdout_end = 202312\n",
    "holdout_data = train[(train['contract_year_month'] >= holdout_start) & (train['contract_year_month'] <= holdout_end)]\n",
    "train_data = train[~(train['contract_year_month'] >= holdout_start) & (train['contract_year_month'] <= holdout_end)]\n",
    "\n",
    "X_train_full = train_data.drop('deposit', axis=1)\n",
    "y_train_full = train_data['deposit']\n",
    "X_holdout = holdout_data.drop('deposit', axis=1)\n",
    "y_holdout = holdout_data['deposit']\n",
    "X_test = test.copy()\n",
    "\n",
    "# 학습 데이터와 검증 데이터 분리\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full,\n",
    "    y_train_full,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'area_m2', 'contract_year_month', 'contract_day',\n",
       "       'contract_type', 'floor', 'built_year', 'latitude', 'longitude', 'age',\n",
       "       'complex_id', 'max_deposit', 'cluster_labels', 'deposit_per_area',\n",
       "       'year', 'mean_deposit_per_area_year', 'pred_deposit_per_area', '_type',\n",
       "       'pred_deposit'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\n",
    "    'contract_type', 'complex_id'\n",
    "]\n",
    "continuous_columns = [\n",
    "    'area_m2', 'contract_year_month', 'floor', 'latitude', 'longitude', 'age',\n",
    "    'max_deposit', 'pred_deposit_per_area', 'pred_deposit'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AutoIntConfig',\n",
       " 'CategoryEmbeddingModelConfig',\n",
       " 'DANetConfig',\n",
       " 'FTTransformerConfig',\n",
       " 'GANDALFConfig',\n",
       " 'GatedAdditiveTreeEnsembleConfig',\n",
       " 'MDNConfig',\n",
       " 'NodeConfig',\n",
       " 'TabNetModelConfig',\n",
       " 'TabTransformerConfig']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_tabular import available_models\n",
    "available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 파라미터\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import TabTransformerConfig, FTTransformerConfig, TabNetModelConfig\n",
    "from pytorch_tabular.config import (\n",
    "    DataConfig,\n",
    "    OptimizerConfig,\n",
    "    TrainerConfig,\n",
    "    ExperimentConfig,\n",
    ")\n",
    "\n",
    "data_config = DataConfig(\n",
    "    target=[\n",
    "        \"deposit\"\n",
    "    ],  # target should always be a list.\n",
    "    continuous_cols=continuous_columns,\n",
    "    categorical_cols=categorical_columns,\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=True,  # Runs the LRFinder to automatically derive a learning rate\n",
    "    batch_size=1024,\n",
    "    max_epochs=100,\n",
    "    early_stopping_mode=\"min\",\n",
    "    early_stopping_patience = \"3\",\n",
    "    min_epochs = 1,\n",
    "\n",
    ")\n",
    "optimizer_config = OptimizerConfig()\n",
    "\n",
    "model_config = FTTransformerConfig(\n",
    "    task=\"regression\",\n",
    "    loss = \"L1Loss\",\n",
    "    metrics = [\"mean_absolute_error\", \"mean_squared_error\"],\n",
    "    target_range = [(int(train_data[\"deposit\"].min() * 0.8), int(train_data[\"deposit\"].max() * 1.2))],\n",
    "    seed = 42,\n",
    ")\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    "    verbose=True,\n",
    "    \n",
    ")\n",
    "tabular_model.fit(train=pd.concat([X_train, y_train], axis=1), validation=pd.concat([X_val, y_val], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FTTransfomer   \n",
    "valid loss : 3880   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = tabular_model.feature_importance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import TabTransformerConfig\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Define the hyperparameters to tune\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [256, 512, 1024])\n",
    "    num_heads = trial.suggest_int(\"num_heads\", 2, 8)\n",
    "    num_attn_blocks = trial.suggest_int(\"num_attn_blocks\", 1, 6)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.5)\n",
    "    \n",
    "    # Set up data config (you can add continuous_cols and categorical_cols as needed)\n",
    "    data_config = DataConfig(\n",
    "        target=[\"deposit\"],\n",
    "        continuous_cols=continuous_columns,\n",
    "        categorical_cols=categorical_columns,\n",
    "    )\n",
    "    \n",
    "    # Set up trainer config\n",
    "    trainer_config = TrainerConfig(\n",
    "        batch_size=batch_size,\n",
    "        max_epochs=100,\n",
    "        early_stopping_mode=\"min\",\n",
    "        early_stopping_patience=3,\n",
    "        min_epochs=1,\n",
    "    )\n",
    "    \n",
    "    # Set up optimizer config with tuned learning rate\n",
    "    optimizer_config = OptimizerConfig(lr=learning_rate)\n",
    "    \n",
    "    # Set up model config with tuned parameters\n",
    "    model_config = TabTransformerConfig(\n",
    "        task=\"regression\",\n",
    "        loss=\"L1Loss\",\n",
    "        metrics=[\"mean_absolute_error\", \"mean_squared_error\"],\n",
    "        target_range=[(int(train_data[\"deposit\"].min() * 0.8), int(train_data[\"deposit\"].max() * 1.2))],\n",
    "        seed=42,\n",
    "        num_heads=num_heads,\n",
    "        num_attn_blocks=num_attn_blocks,\n",
    "        dropout=dropout,\n",
    "    )\n",
    "    \n",
    "    # Build the model\n",
    "    tabular_model = TabularModel(\n",
    "        data_config=data_config,\n",
    "        model_config=model_config,\n",
    "        optimizer_config=optimizer_config,\n",
    "        trainer_config=trainer_config,\n",
    "        verbose=False,\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    tabular_model.fit(train=pd.concat([X_train, y_train], axis=1), validation=pd.concat([X_val, y_val], axis=1))\n",
    "    \n",
    "    # Evaluate on validation set and return validation metric (e.g., MAE)\n",
    "    result = tabular_model.evaluate(val=pd.concat([X_holdout, y_holdout], axis=1)) ## holdout에 대한 MSE\n",
    "    \n",
    "    # Optuna will minimize the objective, so return the validation MAE\n",
    "    return result['valid_mean_absolute_error']\n",
    "\n",
    "# Create a study and optimize\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"  MAE: {trial.value:.4f}\")\n",
    "print(\"  Best hyperparameters: \", trial.params)\n",
    "\n",
    "# 스터디 결과 저장\n",
    "joblib.dump(study, 'optuna_study_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna 시각화\n",
    "optuna.visualization.plot_optimization_history(study)\n",
    "plt.show()\n",
    "optuna.visualization.plot_param_importances(study)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# holdout 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_pred = tabular_model.predict(pd.concat([X_holdout, pd.DataFrame({'deposit': np.nan}, index=X_holdout.index)], axis=1))\n",
    "holdout_mae = mean_absolute_error(y_holdout, holdout_pred)\n",
    "holdout_rmse = root_mean_squared_error(y_holdout, holdout_pred)\n",
    "\n",
    "print(\"Holdout 데이터셋 성능\")\n",
    "print(f\"LightGBM MAE: {holdout_mae:.2f}\")\n",
    "print(f\"LightGBM RMSE: {holdout_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tab-Transformer\n",
    "Holdout 데이터셋 성능   \n",
    "LightGBM MAE: 5099.32   \n",
    "LightGBM RMSE: 8456.41   \n",
    "\n",
    "### FT-Transformer\n",
    "Holdout 데이터셋 성능   \n",
    "LightGBM MAE: 5099.32   \n",
    "LightGBM RMSE: 8456.41   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 재학습 후 output 생성 (제출용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test split\n",
    "train_data = df[df[\"_type\"] == \"train\"]\n",
    "test_data = df[df[\"_type\"] == \"test\"]\n",
    "\n",
    "X_train_full = train_data.drop('deposit', axis=1)\n",
    "y_train_full = train_data['deposit']\n",
    "X_holdout = holdout_data.drop('deposit', axis=1)\n",
    "y_holdout = holdout_data['deposit']\n",
    "X_test = test.copy()\n",
    "\n",
    "# 학습 데이터와 검증 데이터 분리\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full,\n",
    "    y_train_full,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적의 모델로\n",
    "best_params = trial.params\n",
    "learning_rate = best_params[\"learning_rate\"]\n",
    "batch_size = best_params[\"batch_size\"]\n",
    "num_heads = best_params[\"num_heads\"]\n",
    "num_attn_blocks = best_params[\"num_attn_blocks\"]\n",
    "dropout = best_params[\"dropout\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적의 모델로 재학습\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import TabTransformerConfig, TabNetModelConfig\n",
    "from pytorch_tabular.config import (\n",
    "    DataConfig,\n",
    "    OptimizerConfig,\n",
    "    TrainerConfig,\n",
    "    ExperimentConfig,\n",
    ")\n",
    "\n",
    "data_config = DataConfig(\n",
    "    target=[\n",
    "        \"deposit\"\n",
    "    ],  # target should always be a list.\n",
    "    continuous_cols=continuous_columns,\n",
    "    categorical_cols=categorical_columns,\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=True,  # Runs the LRFinder to automatically derive a learning rate\n",
    "    batch_size=batch_size,\n",
    "    max_epochs=100,\n",
    "    early_stopping_mode=\"min\",\n",
    "    early_stopping_patience = \"3\",\n",
    "    min_epochs = 1,\n",
    "\n",
    ")\n",
    "optimizer_config = OptimizerConfig()\n",
    "\n",
    "model_config = TabTransformerConfig(\n",
    "        task=\"regression\",\n",
    "        loss=\"L1Loss\",\n",
    "        metrics=[\"mean_absolute_error\", \"mean_squared_error\"],\n",
    "        target_range=[(int(train_data[\"deposit\"].min() * 0.8), int(train_data[\"deposit\"].max() * 1.2))],\n",
    "        seed=42,\n",
    "        num_heads=num_heads,\n",
    "        num_attn_blocks=num_attn_blocks,\n",
    "        dropout=dropout,\n",
    "    )\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    "    verbose=True,\n",
    "    \n",
    ")\n",
    "tabular_model.fit(train=pd.concat([X_train, y_train], axis=1), validation=pd.concat([X_val, y_val], axis=1))\n",
    "# result = tabular_model.evaluate(test)\n",
    "# pred_df = tabular_model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출용 csv 생성\n",
    "y_test_pred = tabular_model.predict(pd.concat([X_test, pd.DataFrame({'deposit': np.nan}, index=X_holdout.index)], axis=1))\n",
    "sample_submission[\"deposit\"] = y_test_pred\n",
    "sample_submission.to_csv(\"output2.csv\", index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
