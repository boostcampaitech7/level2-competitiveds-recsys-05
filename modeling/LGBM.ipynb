{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# 파일 경로 설정\n",
    "file_path = '../data/'\n",
    "\n",
    "# 파일 불러오기\n",
    "df = pd.read_csv(file_path + 'final.csv')\n",
    "sample_submission = pd.read_csv(file_path + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test split\n",
    "train = df[df[\"_type\"] == \"train\"].sort_values(by='index')\n",
    "test = df[df[\"_type\"] == \"test\"].sort_values(by='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'area_m2',\n",
    "    'contract_type', 'floor', 'age',\n",
    "    'previous_month_interest_rate',\n",
    "    'monthly_new_supply', 'complex_id', 'max_deposit', 'contract_year',\n",
    "    'contract_month', 'mean_cluster_prophet',\n",
    "    'max_deposit_per_area', 'previous_deposit',\n",
    "    'half_max_deposit', 'deposit_std_id', \n",
    "    'nearest_subway_distance_km', 'nearest_elementary_distance_km',\n",
    "    'nearest_middle_distance_km', 'nearest_high_distance_km',\n",
    "    'nearest_park_distance_km', 'nearest_park_area',\n",
    "    'num_subway_within_0_5', 'num_subway_within_1', 'num_subway_within_3',\n",
    "    'num_elementary_within_0_5', 'num_elementary_within_1',\n",
    "    'num_elementary_within_2', 'num_middle_within_0_5',\n",
    "    'num_middle_within_1', 'num_middle_within_2', 'num_high_within_0_5',\n",
    "    'num_high_within_1', 'num_high_within_2', 'num_park_within_0_8',\n",
    "    'num_park_within_1_5', 'num_park_within_2', 'area_floor_interaction',\n",
    "    'pred_deposit', 'deposit_label'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_start = 202307\n",
    "holdout_end = 202312\n",
    "holdout_data = train[(train['contract_year_month'] >= holdout_start) & (train['contract_year_month'] <= holdout_end)]\n",
    "train_data = train[~(train['contract_year_month'] >= holdout_start) & (train['contract_year_month'] <= holdout_end)]\n",
    "\n",
    "X_train_full = train_data[columns]\n",
    "y_train_full = train_data['deposit']\n",
    "X_holdout = holdout_data[columns]\n",
    "y_holdout = holdout_data['deposit']\n",
    "X_test = test[columns]\n",
    "\n",
    "# 학습 데이터와 검증 데이터 분리\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full,\n",
    "    y_train_full,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-22 20:22:50,587] A new study created in memory with name: no-name-a2877491-5d7c-45e3-bdb5-db7f24a4b630\n",
      "[I 2024-10-22 20:23:05,369] Trial 0 finished with value: 3554.7741276868805 and parameters: {'learning_rate': 0.05, 'n_estimators': 236, 'max_depth': 6, 'num_leaves': 59, 'subsample': 0.8229712986890121, 'colsample_bytree': 0.5527710729445382}. Best is trial 0 with value: 3554.7741276868805.\n",
      "[I 2024-10-22 20:23:24,680] Trial 1 finished with value: 3978.566607901115 and parameters: {'learning_rate': 0.01, 'n_estimators': 386, 'max_depth': 4, 'num_leaves': 44, 'subsample': 0.5052193771262447, 'colsample_bytree': 0.6538490083145556}. Best is trial 0 with value: 3554.7741276868805.\n",
      "[I 2024-10-22 20:23:39,397] Trial 2 finished with value: 4881.349164051652 and parameters: {'learning_rate': 0.01, 'n_estimators': 226, 'max_depth': 5, 'num_leaves': 65, 'subsample': 0.8830531989791914, 'colsample_bytree': 0.7545042248321863}. Best is trial 0 with value: 3554.7741276868805.\n",
      "[I 2024-10-22 20:23:53,548] Trial 3 finished with value: 5395.932938354851 and parameters: {'learning_rate': 0.01, 'n_estimators': 319, 'max_depth': 2, 'num_leaves': 42, 'subsample': 0.981728853718826, 'colsample_bytree': 0.7738995778734175}. Best is trial 0 with value: 3554.7741276868805.\n",
      "[I 2024-10-22 20:23:59,086] Trial 4 finished with value: 11198.701592956344 and parameters: {'learning_rate': 0.01, 'n_estimators': 71, 'max_depth': 4, 'num_leaves': 90, 'subsample': 0.9422263408645482, 'colsample_bytree': 0.8882986492228697}. Best is trial 0 with value: 3554.7741276868805.\n",
      "[I 2024-10-22 20:24:19,747] Trial 5 finished with value: 3459.2323178265524 and parameters: {'learning_rate': 0.2, 'n_estimators': 316, 'max_depth': 13, 'num_leaves': 52, 'subsample': 0.9955455067172012, 'colsample_bytree': 0.8134900001975958}. Best is trial 5 with value: 3459.2323178265524.\n",
      "[I 2024-10-22 20:24:49,594] Trial 6 finished with value: 3423.8923097843153 and parameters: {'learning_rate': 0.05, 'n_estimators': 422, 'max_depth': 16, 'num_leaves': 99, 'subsample': 0.5320853370339209, 'colsample_bytree': 0.5368064402475419}. Best is trial 6 with value: 3423.8923097843153.\n",
      "[I 2024-10-22 20:25:09,159] Trial 7 finished with value: 3519.4397527953847 and parameters: {'learning_rate': 0.2, 'n_estimators': 339, 'max_depth': 12, 'num_leaves': 55, 'subsample': 0.9048306563958002, 'colsample_bytree': 0.5003194244221664}. Best is trial 6 with value: 3423.8923097843153.\n",
      "[I 2024-10-22 20:25:36,627] Trial 8 finished with value: 3432.2861341145936 and parameters: {'learning_rate': 0.2, 'n_estimators': 386, 'max_depth': 12, 'num_leaves': 71, 'subsample': 0.5821656914408582, 'colsample_bytree': 0.8326437236004586}. Best is trial 6 with value: 3423.8923097843153.\n",
      "[I 2024-10-22 20:25:38,486] Trial 9 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-10-22 20:25:57,284] Trial 10 pruned. Trial was pruned at iteration 236.\n",
      "[I 2024-10-22 20:26:29,035] Trial 11 finished with value: 3402.6498239950097 and parameters: {'learning_rate': 0.1, 'n_estimators': 460, 'max_depth': 16, 'num_leaves': 74, 'subsample': 0.6480496405246629, 'colsample_bytree': 0.6330797289287086}. Best is trial 11 with value: 3402.6498239950097.\n",
      "[I 2024-10-22 20:26:35,918] Trial 12 pruned. Trial was pruned at iteration 89.\n",
      "[I 2024-10-22 20:26:51,353] Trial 13 pruned. Trial was pruned at iteration 236.\n",
      "[I 2024-10-22 20:27:09,791] Trial 14 pruned. Trial was pruned at iteration 226.\n",
      "[I 2024-10-22 20:27:16,527] Trial 15 finished with value: 3623.4743717874353 and parameters: {'learning_rate': 0.1, 'n_estimators': 79, 'max_depth': 9, 'num_leaves': 83, 'subsample': 0.5053520827298057, 'colsample_bytree': 0.5007818341459069}. Best is trial 11 with value: 3402.6498239950097.\n",
      "[I 2024-10-22 20:27:18,939] Trial 16 pruned. Trial was pruned at iteration 8.\n",
      "[I 2024-10-22 20:27:35,268] Trial 17 finished with value: 3480.7102797934353 and parameters: {'learning_rate': 0.1, 'n_estimators': 210, 'max_depth': 11, 'num_leaves': 90, 'subsample': 0.7398899376022381, 'colsample_bytree': 0.5826378941820318}. Best is trial 11 with value: 3402.6498239950097.\n",
      "[I 2024-10-22 20:27:37,165] Trial 18 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-10-22 20:27:43,543] Trial 19 pruned. Trial was pruned at iteration 71.\n",
      "[I 2024-10-22 20:27:45,541] Trial 20 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-10-22 20:28:11,849] Trial 21 finished with value: 3433.586359065913 and parameters: {'learning_rate': 0.2, 'n_estimators': 395, 'max_depth': 12, 'num_leaves': 71, 'subsample': 0.5668592128929727, 'colsample_bytree': 0.8556576451595366}. Best is trial 11 with value: 3402.6498239950097.\n",
      "[I 2024-10-22 20:28:36,342] Trial 22 finished with value: 3447.2751256079205 and parameters: {'learning_rate': 0.2, 'n_estimators': 364, 'max_depth': 16, 'num_leaves': 77, 'subsample': 0.613367673237314, 'colsample_bytree': 0.9140728020893238}. Best is trial 11 with value: 3402.6498239950097.\n",
      "[I 2024-10-22 20:29:05,180] Trial 23 finished with value: 3457.314823042091 and parameters: {'learning_rate': 0.2, 'n_estimators': 426, 'max_depth': 14, 'num_leaves': 67, 'subsample': 0.5424688090678931, 'colsample_bytree': 0.8034850646289565}. Best is trial 11 with value: 3402.6498239950097.\n",
      "[I 2024-10-22 20:29:07,227] Trial 24 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-10-22 20:29:23,465] Trial 25 pruned. Trial was pruned at iteration 236.\n",
      "[I 2024-10-22 20:29:25,393] Trial 26 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-10-22 20:29:51,272] Trial 27 finished with value: 3420.047161478626 and parameters: {'learning_rate': 0.2, 'n_estimators': 350, 'max_depth': 15, 'num_leaves': 81, 'subsample': 0.7829569627445632, 'colsample_bytree': 0.61283026464072}. Best is trial 11 with value: 3402.6498239950097.\n",
      "[I 2024-10-22 20:29:53,459] Trial 28 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-10-22 20:29:55,495] Trial 29 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-10-22 20:30:11,453] Trial 30 pruned. Trial was pruned at iteration 236.\n",
      "[I 2024-10-22 20:30:35,763] Trial 31 pruned. Trial was pruned at iteration 345.\n",
      "[I 2024-10-22 20:30:51,580] Trial 32 pruned. Trial was pruned at iteration 236.\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "    'boosting_type': trial.suggest_categorical('boosting_type', ['gbdt']),\n",
    "    'learning_rate': trial.suggest_categorical('learning_rate', [0.05, 0.01, 0.1, 0.2]),\n",
    "    'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "    'max_depth': trial.suggest_int('max_depth', 1, 16),\n",
    "    'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "    'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "    'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "    'objective': trial.suggest_categorical('objective', ['regression_l1']),\n",
    "    'random_state': trial.suggest_categorical('random_state', [42]),\n",
    "    'verbose': trial.suggest_categorical('verbose', [-1])\n",
    "    }\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "    \n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_metric='mae',\n",
    "        callbacks=[optuna.integration.LightGBMPruningCallback(trial, 'l1'), lgb.early_stopping(50, verbose=False)]\n",
    "    )\n",
    "    \n",
    "    holdout_pred = model.predict(X_holdout)\n",
    "    \n",
    "    holdout_mae = mean_absolute_error(y_holdout, holdout_pred)\n",
    "    holdout_rmse = root_mean_squared_error(y_holdout, holdout_pred)\n",
    "\n",
    "    trial.set_user_attr(\"rmse\", holdout_rmse)\n",
    "    \n",
    "    return holdout_mae\n",
    "  \n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# holdout 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "MAE: 437.5441706557971\n",
      "RMSE: 2363.604400600384\n",
      "Best hyperparameters:  {'boosting_type': 'gbdt', 'learning_rate': 0.2, 'n_estimators': 434, 'max_depth': 11, 'num_leaves': 77, 'subsample': 0.7114015114488768, 'colsample_bytree': 0.7545544258259315}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(f\"MAE: {trial.value}\")\n",
    "print(f\"RMSE: {trial.user_attrs['rmse']}\")\n",
    "print(\"Best hyperparameters: \", trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 재학습 후 output 생성 (제출용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014728 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3064\n",
      "[LightGBM] [Info] Number of data points in the train set: 1448728, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 37593.700393\n",
      " MAE: 341.00\n",
      " RMSE: 706.42\n"
     ]
    }
   ],
   "source": [
    "# 재학습\n",
    "best_params = trial.params\n",
    "best_model = lgb.LGBMRegressor(**best_params)\n",
    "\n",
    "best_model.fit(train[columns], train['deposit'])\n",
    "\n",
    "y_pred = best_model.predict(train[columns])\n",
    "y_test_pred = best_model.predict(test[columns])\n",
    "\n",
    "mae = mean_absolute_error(train['deposit'], y_pred)\n",
    "rmse = root_mean_squared_error(train['deposit'], y_pred)\n",
    "\n",
    "print(f\" MAE: {mae:.2f}\")\n",
    "print(f\" RMSE: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출용 csv 생성\n",
    "sample_submission[\"deposit\"] = y_test_pred\n",
    "sample_submission.to_csv(\"output.csv\", index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
